# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

Jazzapedia is a Wikipedia-style encyclopedia for 4,000+ musician profiles. Built with Astro in SSR mode, it serves pages dynamically from a Cloudflare D1 database.

**Live Site:** https://jazzapedia.com

**Stats:** 4,131 artists, 466 genres, 166 instruments

## Architecture

### Server-Side Rendering (SSR)

The site uses Astro with `output: 'server'` and the `@astrojs/cloudflare` adapter. All pages query the D1 database at request time rather than being pre-built.

### Cloudflare Stack

- **Pages**: Hosts the Astro SSR application
- **D1**: SQLite database storing all artist data
- **R2**: Object storage for artist portraits at `media.jazzapedia.com`

### Database Access

Pages access D1 via runtime bindings:
```typescript
const db = Astro.locals.runtime?.env?.DB;
const result = await db.prepare('SELECT * FROM artists WHERE slug = ?').bind(slug).first();
```

### Key Files

- `wrangler.toml` - D1 binding config (must have `pages_build_output_dir` for Pages)
- `astro.config.mjs` - SSR config with Cloudflare adapter
- `src/pages/` - All route handlers querying D1
- `src/components/Infobox.astro` - Wikipedia-style sidebar with artist metadata

## Commands

```bash
npm run dev          # Start dev server (uses LOCAL D1 database)
npm run build        # Build SSR bundle to ./dist/
npm run preview      # Preview built site
```

For deployment:
```bash
npm run build
npx pagefind --site dist
npx wrangler pages deploy dist --project-name jazzapedia
```

## Database Schema

### artists table
```sql
CREATE TABLE artists (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  slug TEXT UNIQUE NOT NULL,
  title TEXT NOT NULL,
  artist_type TEXT,              -- 'person' or 'band'
  birth_date TEXT,
  death_date TEXT,
  origin TEXT,                   -- Location for bands
  birth_place TEXT,              -- Birth location for individuals
  bio_html TEXT,                 -- Rendered HTML content
  bio_markdown TEXT,             -- Original markdown
  image_filename TEXT,
  genres TEXT DEFAULT '[]',           -- JSON array
  instruments TEXT DEFAULT '[]',      -- JSON array
  roles TEXT DEFAULT '[]',            -- JSON array
  spotify_data TEXT DEFAULT '{}',     -- JSON object
  audio_profile TEXT DEFAULT '{}',    -- JSON object
  musical_connections TEXT DEFAULT '{}',  -- JSON object
  external_urls TEXT DEFAULT '{}',    -- JSON object
  social_links TEXT DEFAULT '{}',     -- JSON object
  discography_summary TEXT DEFAULT '{}', -- JSON object
  research_sources TEXT DEFAULT '[]', -- JSON array of Perplexity source URLs
  career_span TEXT,
  is_active INTEGER DEFAULT 1,
  primary_role TEXT,
  created_at TEXT,
  updated_at TEXT
);
```

### genres / instruments / roles tables
```sql
CREATE TABLE genres (
  id INTEGER PRIMARY KEY,
  name TEXT UNIQUE NOT NULL,
  slug TEXT UNIQUE NOT NULL,
  artist_count INTEGER DEFAULT 0
);
-- Same structure for instruments and roles tables
```

## Local Development

### Local vs Remote D1

The dev server uses a **local D1 database** stored in `.wrangler/state/v3/d1/`. This is completely separate from production.

```bash
npm run dev  # Connects to LOCAL D1 (not production)
```

### Syncing Data to Local D1

To populate or update your local database:
```bash
# Sync artist markdown files to local D1
npx tsx scripts/sync-to-d1.ts --local

# Or sync to production
npx tsx scripts/sync-to-d1.ts --remote
```

### Running Migrations

```bash
# Apply to local D1
npx wrangler d1 execute jazzapedia --file=migrations/XXX.sql --local

# Apply to production D1
npx wrangler d1 execute jazzapedia --file=migrations/XXX.sql --remote
```

## Data Pipeline

### Source Data

Artist markdown files live in an Obsidian vault at:
```
/Users/maxwell/LETSGO/MaxVault/01_Projects/PersonalArtistWiki/Artists/
```

These are generated by the artist discovery pipeline (`/Users/maxwell/Projects/wwoz-scraper-v3/artist_discovery_pipeline.py`) which uses Spotify, MusicBrainz, and Perplexity AI for research.

### Sync Script (`scripts/sync-to-d1.ts`)

Reads markdown files, parses frontmatter, converts to HTML, and batch-inserts into D1:

```bash
npx tsx scripts/sync-to-d1.ts --local          # Sync to local D1
npx tsx scripts/sync-to-d1.ts --remote         # Sync to production D1
npx tsx scripts/sync-to-d1.ts --remote --dry-run  # Preview without changes
```

The script:
- Parses YAML frontmatter for metadata
- Converts markdown body to HTML
- Finds matching portrait images
- Generates SQL batches in `./sync-output/`
- Executes against D1

### Backfill Script (`scripts/backfill-origin-sources.ts`)

Extracts data from existing `bio_html` to populate new columns:

```bash
npx tsx scripts/backfill-origin-sources.ts --local --dry-run  # Preview
npx tsx scripts/backfill-origin-sources.ts --local            # Execute
npx tsx scripts/backfill-origin-sources.ts --remote           # Production
```

## Page Patterns

### Artist Pages (`src/pages/artists/[...slug].astro`)

- Fetches artist from D1 by slug
- Parses JSON fields (genres, instruments, spotify_data, etc.)
- Strips redundant Quick Info section from bio_html
- Extracts research sources for References section
- Renders Infobox, bio content, WWOZ plays, and Connection Graph

### Infobox Component

The infobox displays differently for bands vs individuals:
- **Bands**: Shows "Formed" date + "Origin" location, "Group" badge
- **Individuals**: Shows "Born" date + birthPlace, "Artist" badge

### References Section

Perplexity research sources are displayed as a numbered list before the Connection Graph. Sources are either:
1. Stored in `research_sources` column (preferred)
2. Extracted from `bio_html` as fallback (legacy)

## Image URLs

Portraits are served from R2:
```typescript
const portraitUrl = `https://media.jazzapedia.com/portraits/${artist.image_filename}`;
```

## Caching

Pages set cache headers for edge caching:
```typescript
Astro.response.headers.set('Cache-Control', 'public, max-age=60, stale-while-revalidate=86400');
```

## Deployment

GitHub Actions workflow (`.github/workflows/deploy.yml`) runs on push to master:
1. `npm ci` - Install dependencies
2. `npm run build` - Build Astro SSR bundle
3. `npx pagefind --site dist` - Generate search index
4. `npx wrangler pages deploy dist --project-name jazzapedia` - Deploy with D1 binding

**Note:** Code deploys automatically. Database syncs can be triggered via GitHub Actions (see below).

## Automated Daily Sync

The system automatically syncs new artists daily at 5am CT to both Docker (SQLite) and Cloudflare (D1/R2).

### Architecture

```
                    4:30am CT (launchd)
                           │
                           ▼
            ┌─────────────────────────────┐
            │   unified-daily-sync.sh     │
            └─────────────────────────────┘
                           │
       ┌───────────────────┼───────────────────┐
       │                   │                   │
       ▼                   ▼                   ▼
   Vault → Git      Vault → SQLite         Portraits rsync
   (auto-sync)      (INCREMENTAL)          (only new files)
       │                   │                   │
       ▼                   ▼                   ▼
   Git push        ./data/jazzapedia.db   ./portraits/
       │                   │                   │
       ▼                   └─────────┬─────────┘
   5:00am CT                        │
   GitHub Actions                   ▼
   (D1 incremental)    docker-compose restart
       │                  (only if changes)
       ▼
   D1 + R2 (Cloudflare)
```

### Daily Sync Timeline

- **4:30am CT**: `unified-daily-sync.sh` runs via launchd
  - Syncs vault → SQLite (incremental, content-hash based)
  - Syncs WWOZ archives → `src/content/wwoz/` (incremental)
  - Syncs portraits for Docker
  - Restarts Docker container if changes detected
  - Commits artists + WWOZ archives → git push (triggers GitHub Actions)
- **5:00am CT**: GitHub Actions runs D1 incremental sync + R2 upload

### Sync Commands

```bash
# Incremental syncs (only new/modified artists)
npm run sync:incr:sqlite          # Sync to SQLite (Docker)
npm run sync:incr:remote          # Sync to D1 (Cloudflare)

# Full syncs (all artists)
npm run sync:sqlite               # Full SQLite sync
npm run sync:remote               # Full D1 sync

# WWOZ archive syncs
npm run sync:wwoz                 # Sync WWOZ archives to content directory
npm run sync:wwoz:dry-run         # Preview WWOZ sync

# Orchestrated sync (both Docker + Cloudflare)
npm run sync:all                  # Run unified daily sync (includes WWOZ)
npm run sync:all -- --dry-run     # Preview only
npm run sync:all -- --skip-git    # Skip git push (SQLite only)

# Verification
npm run sync:verify               # Compare counts across vault/SQLite/D1
```

### Incremental Sync

Both D1 and SQLite use content-hash based incremental sync:
- Computes MD5 hash of each markdown file
- Compares against `content_hash` column in database
- Only syncs new or modified artists
- Much faster than full sync (~2s vs ~30s for typical daily updates)

### launchd Configuration

The daily sync is scheduled via macOS launchd:

```bash
# Load the scheduler
cp scripts/com.jazzapedia.daily-sync.plist ~/Library/LaunchAgents/
launchctl load ~/Library/LaunchAgents/com.jazzapedia.daily-sync.plist

# Check status
launchctl list | grep jazzapedia

# Manual trigger
launchctl start com.jazzapedia.daily-sync

# Unload
launchctl unload ~/Library/LaunchAgents/com.jazzapedia.daily-sync.plist
```

### Key Sync Scripts

| Script | Purpose |
|--------|---------|
| `scripts/unified-daily-sync.sh` | Master orchestrator for daily sync |
| `scripts/sync-incremental-sqlite.ts` | Incremental SQLite sync |
| `scripts/sync-incremental.ts` | Incremental D1 sync |
| `scripts/sync-to-sqlite.ts` | Full SQLite sync |
| `scripts/sync-to-d1.ts` | Full D1 sync |
| `scripts/sync-wwoz.ts` | WWOZ archive sync to content directory |
| `scripts/verify-sync.sh` | Health check across all databases |
| `scripts/auto-sync-vault.sh` | Vault → git sync |

## GitHub Actions Sync

A GitHub Actions workflow (`.github/workflows/sync-artists.yml`) syncs new artists to D1 and uploads portraits to R2.

### Schedule

- **Daily at 5:00am CT** (11:00 UTC) - Automatic incremental sync
- **Manual trigger** via GitHub Actions UI (workflow_dispatch)

### Workflow Features

- **Incremental sync**: Only syncs new/modified artists (content-hash based)
- **Full sync option**: Available via manual trigger
- **R2 upload**: Uploads new portraits only (skips existing files)
- **Dry-run option**: Preview changes without applying

### Adding New Artists (Manual Workflow)

```bash
# 1. Run artist discovery pipeline (generates new markdown in Obsidian vault)

# 2. Sync vault content to repo
npm run sync:content-deploy

# 3. Commit and push
git add content-deploy
git commit -m "Add new artists"
git push

# 4. GitHub Actions will sync automatically, or trigger manually:
# Go to: GitHub > Actions > "Sync Artists to Jazzapedia" > Run workflow
```

### Environment Variables

The sync scripts support configurable paths via environment variables:
- `ARTISTS_DIR` - Path to artist markdown files (default: Obsidian vault)
- `PORTRAITS_DIR` - Path to portrait images (default: Obsidian vault)

GitHub Actions sets these to `./content-deploy/artists` and `./content-deploy/portraits`.

## Common Tasks

### Adding a new page
1. Create `.astro` file in `src/pages/`
2. Access D1 via `Astro.locals.runtime?.env?.DB`
3. Set appropriate cache headers
4. Handle `db` being undefined gracefully

### Modifying database schema
1. Create migration in `migrations/`
2. Apply locally: `npx wrangler d1 execute jazzapedia --file=migrations/XXX.sql --local`
3. Test with `npm run dev`
4. Apply to production: `npx wrangler d1 execute jazzapedia --file=migrations/XXX.sql --remote`

### Full data refresh
```bash
# 1. Run pipeline to generate/update artist cards (separate repo)
# 2. Sync vault to content-deploy
npm run sync:content-deploy
# 3. Commit and push
git add content-deploy && git commit -m "Update artists" && git push
# 4. Run "Sync Artists to Jazzapedia" workflow in GitHub Actions
```

For manual/local sync (without GitHub Actions):
```bash
npx tsx scripts/sync-to-d1.ts --remote        # Sync to D1
npx tsx scripts/upload-portraits-r2.ts        # Upload portraits to R2
```

### Updating wrangler.toml
- Keep `pages_build_output_dir = "dist"` - required for D1 bindings
- D1 binding must use `binding = "DB"` to match code expectations

## Docker Containerization

**IMPORTANT: Docker serves as the testing/staging environment.** Always verify changes work in Docker before deploying to Cloudflare production. The Docker environment mirrors production behavior but uses SQLite instead of D1.

The site can run in Docker with a local SQLite database instead of Cloudflare D1.

### Architecture

```
┌──────────────────────────────────────────────────────────┐
│                   Docker Compose                          │
│  ┌────────────────────────────────────────────────────┐  │
│  │              nginx (port 80)                        │  │
│  │   /portraits/* → static files                       │  │
│  │   /*          → proxy to Astro                      │  │
│  └─────────────────────┬──────────────────────────────┘  │
│                        │                                  │
│  ┌─────────────────────▼──────────────────────────────┐  │
│  │            jazzapedia (port 4321)                   │  │
│  │           Astro SSR + @astrojs/node                 │  │
│  │           + better-sqlite3                          │  │
│  └─────────────────────────────────────────────────────┘  │
│                                                           │
│  Volumes:                                                 │
│   ./data/jazzapedia.db  (SQLite database)                │
│   ./portraits/          (4,000+ artist images)           │
└───────────────────────────────────────────────────────────┘
```

### Quick Start

```bash
# 1. Sync artist data to SQLite
npm run sync:sqlite

# 2. Sync portrait images
rsync -av /path/to/vault/ArtistPortraits/ ./portraits/

# 3. Build and run
docker-compose up -d --build

# Site available at http://localhost
```

### Docker Commands

```bash
npm run docker:build    # Build containers
npm run docker:up       # Start containers
npm run docker:down     # Stop containers
npm run docker:logs     # View logs

# Database sync
npm run sync:sqlite              # Full sync to SQLite
npm run sync:incr:sqlite         # Incremental sync (faster, recommended)
npm run sync:incr:sqlite:dry-run # Preview incremental changes

# Unified sync (SQLite + portraits + container restart)
npm run sync:all -- --skip-git   # Sync without git push
```

### Key Files

- `Dockerfile` - Multi-stage build (Node.js + better-sqlite3)
- `docker-compose.yml` - App + nginx orchestration
- `nginx.conf` - Reverse proxy with portrait caching
- `src/lib/db.ts` - Database abstraction layer (D1 + SQLite)
- `src/data/artist-slugs.json` - Static artist slug index (see below)
- `scripts/sync-to-sqlite.ts` - Full SQLite sync
- `scripts/sync-incremental-sqlite.ts` - Incremental SQLite sync (recommended)
- `scripts/generate-artist-slugs.ts` - Generate artist slug index
- `scripts/unified-daily-sync.sh` - Daily sync orchestrator

### Artist Slug Index

The file `src/data/artist-slugs.json` contains all artist slugs from the database. It's used by WWOZ archive pages to link artist names without runtime database queries.

**Why it exists:**
- WWOZ pages (`/wwoz/[date]`) need to know if an artist has a profile page
- Runtime D1 queries are unreliable in some SSR contexts
- A static index is faster and more reliable

**When to regenerate:**
- After adding new artists to the database
- The `unified-daily-sync.sh` script regenerates it automatically
- Manual regeneration: `npm run generate:slugs`

**IMPORTANT:** This file is committed to git. If you add artists manually, regenerate the index before testing in Docker or deploying.

### Environment Variable

Set `DEPLOY_TARGET=docker` to use SQLite instead of D1. This switches:
- Astro adapter from `@astrojs/cloudflare` to `@astrojs/node`
- Database from D1 bindings to better-sqlite3
- Portrait URLs from R2 to local `/portraits/` path

### Database Abstraction

Pages use `getDatabase()` which returns the appropriate adapter:

```typescript
import { getDatabase } from '../lib/db';
const db = await getDatabase(Astro.locals);
const result = await db.prepare('SELECT * FROM artists').all();
```
